{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FfG3xQvgyHx2"
      },
      "outputs": [],
      "source": [
        "import torch, torch.nn as nn, numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import pandas as pd\n",
        "import emoji"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "In this section, we load and process data using the `SarcasmDataset` class. To create a `SarcasmDataset`, input the path of the data csv file and the tokenizer. Later use pytorch to crate a dataloader for the dataset (in the main script)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SarcasmDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_path, tokenizer, max_len, target_col_names=['tweet', 'sarcastic']):\n",
        "        ''' \n",
        "        data_path: path to csv file\n",
        "        tokenizer: tokenizer to use, likely load from AutoTokenizer\n",
        "        max_len: max length of input sequence\n",
        "        '''\n",
        "        self.data_path = data_path\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.data = self.load_data(target_col_names)\n",
        "\n",
        "    def load_data(self, target_col_names):\n",
        "        # use pandas to read csv file\n",
        "        df = pd.read_csv(self.data_path)\n",
        "        # only need certain columns\n",
        "        df = df[target_col_names]\n",
        "        # replace nan with empty string\n",
        "        df = df.fillna('')\n",
        "        # convert to np array\n",
        "        data = df.values\n",
        "        # convert posible emoji to text\n",
        "        data = [[emoji.demojize(text), label] for text, label in data]\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Convert text to tokens, add special tokens, and create attention mask\n",
        "        return: input_ids, attention_mask, label\n",
        "        '''\n",
        "        text, label = self.data[idx]\n",
        "        tokens = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            add_special_tokens=True\n",
        "        )\n",
        "        input_ids = tokens['input_ids']\n",
        "        attention_mask = tokens['attention_mask']\n",
        "        return torch.tensor(input_ids), torch.tensor(attention_mask), torch.tensor(label)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model\n",
        "\n",
        "In this section, we define the model. We will use the ensemble method, which would use multiple models and combine their outputs to get the final prediction.\n",
        "\n",
        "The pretrained models are defined in `PretrainedModelPlus` class, which can take in any pretrained model and add a hidden layer and output layer on top of it. \n",
        "\n",
        "### Ensembling\n",
        "\n",
        "The models are trained separately and the outputs are combined using combined probability. This is implemented in the predict function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PretrainedModelPlus(nn.Module):\n",
        "    def __init__(self, pretrained_model, output_size, linear_layer_size):\n",
        "        super(PretrainedModelPlus, self).__init__()\n",
        "        self.pretrained_model = pretrained_model\n",
        "        # Add a linear layer on top of the pretrained model\n",
        "        self.linear = nn.Linear(self.pretrained_model.config.hidden_size, linear_layer_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(linear_layer_size, output_size)\n",
        "        # Add a sigmoid layer to get the probabilities\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        # Define the loss function\n",
        "        self.loss = nn.BCELoss()\n",
        "\n",
        "\n",
        "    def forward(self, x, attention_mask, labels):\n",
        "        pretrained_outputs = self.pretrained_model(input_ids=x, attention_mask=attention_mask, \n",
        "                                                   return_dict=True, output_hidden_states=True)\n",
        "\n",
        "        hidden_states = torch.stack(pretrained_outputs[\"hidden_states\"])\n",
        "        cat_hidden_states = torch.cat([hidden_states[i] for i in [-1, -2, -3, -4]], dim=1)\n",
        "        first_token = cat_hidden_states[:, 0, :]\n",
        "\n",
        "        linear_outputs = self.linear(first_token)\n",
        "        activation_outputs = self.relu(linear_outputs)\n",
        "        output = self.linear2(activation_outputs)\n",
        "        probs = self.sigmoid(output)\n",
        "        loss = self.loss(probs.view(-1), labels.float())\n",
        "        return loss, probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def trian(model, dataloader, epochs=3, learning_rate=1e-5):\n",
        "    ''' Train a model\n",
        "    model: model to train\n",
        "    dataloader: data loader to use\n",
        "    epochs: number of epochs to train\n",
        "    learning_rate: learning rate to use\n",
        "    return: trained model\n",
        "    '''\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "    for epoch in range(epochs):\n",
        "        num_tp = 0\n",
        "        num_fp = 0\n",
        "        num_tn = 0\n",
        "        num_fn = 0\n",
        "\n",
        "        model.train()\n",
        "        for input_ids, attention_mask, labels in tqdm(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            loss, probs = model(input_ids, attention_mask, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = torch.round(probs)\n",
        "            # compare to labels and update tp, fp, tn, fn\n",
        "            num_tp += ((preds == 1) & (labels == 1)).sum().item()\n",
        "            num_fp += ((preds == 1) & (labels == 0)).sum().item()\n",
        "            num_tn += ((preds == 0) & (labels == 0)).sum().item()\n",
        "            num_fn += ((preds == 0) & (labels == 1)).sum().item()\n",
        "\n",
        "        accuracy = (num_tp + num_tn) / (num_tp + num_fp + num_tn + num_fn)\n",
        "        f1 = 2 * (num_tp / (2 * num_tp + num_fp + num_fn))\n",
        "\n",
        "        # print out stats\n",
        "        print(f'Epoch: {epoch + 1}/{epochs} | Loss: {loss.item():.4f} | Accuracy: {accuracy:.4f} | F1: {f1:.4f}')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(models, data_loaders):\n",
        "    ''' Combine the predictions of models\n",
        "    models: models to use\n",
        "    data_loaders: data loaders to use\n",
        "    return: list of predictions\n",
        "    '''\n",
        "    all_models_probs = []\n",
        "    for data_loader, model in zip(data_loaders, models):\n",
        "        probs = []\n",
        "        for input_ids, attention_mask, labels in tqdm(data_loader):\n",
        "            _, prob = model(input_ids, attention_mask, labels)\n",
        "            prob = prob.detach().numpy()[0][0]\n",
        "            probs.append(prob)\n",
        "        all_models_probs.append(probs)\n",
        "    ensemble_probs = np.array(all_models_probs).mean(axis=0)\n",
        "    preds = [1 if prob > 0.5 else 0 for prob in ensemble_probs]\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_pred_from_test_file(models, model_names, test_file, output_file=\"output.csv\"):\n",
        "    ''' Generate predictions from a file\n",
        "    models: list of pretrained models\n",
        "    model_names: list of names of models to use\n",
        "    test_file: file to use for testing\n",
        "    output_file: file to save the predictions\n",
        "    '''\n",
        "    tokenizers = [AutoTokenizer.from_pretrained(model_name) for model_name in model_names]\n",
        "    test_datasets = [SarcasmDataset(test_file, tokenizer, max_len=128, target_col_names=['text', 'sarcastic']) for tokenizer in tokenizers]\n",
        "    test_dataloaders = [torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False) for test_dataset in test_datasets]\n",
        "\n",
        "    preds = predict(models, test_dataloaders)\n",
        "    df = pd.read_csv(test_file)\n",
        "    df['sarcastic'] = preds\n",
        "    df = df[['text', 'sarcastic']]\n",
        "    df.to_csv(output_file, index=False)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation Matrics\n",
        "\n",
        "We use the f1 score as the evaluation matrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5fJMx7En68GD"
      },
      "outputs": [],
      "source": [
        "def evaluate_f1(test_file, model_generated_file):\n",
        "  '''\n",
        "  Inputs a test file and file generated by the model and returns the f1 score using f1_score from sklearn.metrics\n",
        "  :param test_file: csv of shape(num_samples, num_classifications)\n",
        "  :param model_generated_file: csv of shape(num_samples, num_classifications)\n",
        "  :return: f1_score of test_file and model_generated_file of shape(1)\n",
        "  '''\n",
        "  df1 = pd.read_csv(test_file)\n",
        "  df2 = pd.read_csv(model_generated_file)\n",
        "  arr1 = df1['sarcastic'].to_numpy()\n",
        "  arr2 = df2['sarcastic'].to_numpy()\n",
        "\n",
        "  return f1_score(arr1, arr2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Script\n",
        "\n",
        "**Instructions for running the main script:**\n",
        "\n",
        "1. Download the data from [here](https://github.com/iabufarha/iSarcasmEval).\n",
        "\n",
        "2. Create the dataset and dataloader for each of the models.\n",
        "\n",
        "3. Create and Train model\n",
        "\n",
        "4. Predict and evaluate f1 score on test set\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataset #1\n",
        "dataset_roberta = SarcasmDataset(data_path='iSarcasmEval/train/train.En.csv',\n",
        "                                 tokenizer=AutoTokenizer.from_pretrained('roberta-base'),\n",
        "                                 max_len=128)\n",
        "# Create data loader #1\n",
        "dataloader_roberta = torch.utils.data.DataLoader(dataset_roberta, batch_size=32, shuffle=True)\n",
        "\n",
        "# Create dataset #2\n",
        "dataset_bertweet = SarcasmDataset(data_path='iSarcasmEval/train/train.En.csv',\n",
        "                                   tokenizer=AutoTokenizer.from_pretrained('finiteautomata/bertweet-base-sentiment-analysis'),\n",
        "                                   max_len=128)\n",
        "# Create data loader #2\n",
        "dataloader_bertweet = torch.utils.data.DataLoader(dataset_bertweet, batch_size=32, shuffle=True)\n",
        "\n",
        "# Create dataset #3\n",
        "dataset_deberta = SarcasmDataset(data_path='iSarcasmEval/train/train.En.csv',\n",
        "                                tokenizer=AutoTokenizer.from_pretrained('microsoft/deberta-v3-base'),\n",
        "                                max_len=128)\n",
        "# Create data loader #3\n",
        "dataloader_deberta = torch.utils.data.DataLoader(dataset_deberta, batch_size=32, shuffle=True)\n",
        "\n",
        "# Create dataset #4\n",
        "dataset_bertweet_irony = SarcasmDataset(data_path='iSarcasmEval/train/train.En.csv',\n",
        "                                        tokenizer=AutoTokenizer.from_pretrained('pysentimiento/bertweet-irony'),\n",
        "                                        max_len=128)\n",
        "# Create data loader #4\n",
        "dataloader_bertweet_irony = torch.utils.data.DataLoader(dataset_bertweet_irony, batch_size=32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Some sanity checks\n",
        "assert len(dataset_roberta) == 3468\n",
        "assert len(dataset_bertweet) == 3468\n",
        "assert len(dataset_deberta) == 3468"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "sGzAWkNwyvIK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Create models\n",
        "model1 = PretrainedModelPlus(pretrained_model=AutoModel.from_pretrained('roberta-base'), output_size=1, linear_layer_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2 = PretrainedModelPlus(pretrained_model=AutoModel.from_pretrained('finiteautomata/bertweet-base-sentiment-analysis'), output_size=1, linear_layer_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model3 = PretrainedModelPlus(pretrained_model=AutoModel.from_pretrained('microsoft/deberta-v3-base'), output_size=1, linear_layer_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40ab40af919544b3a970f4a2d7e3d6c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/939 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93ce237aa1344a82b6cf034513b0f054",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/540M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at pysentimiento/bertweet-irony were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at pysentimiento/bertweet-irony and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model4 = PretrainedModelPlus(pretrained_model=AutoModel.from_pretrained('pysentimiento/bertweet-irony'), output_size=1, linear_layer_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6707280afbf4412fa2d698c55084d45b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/3 | Loss: 0.3252 | Accuracy: 0.6413 | F1: 0.2533\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b6a776a65574db485652945bea00b01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2/3 | Loss: 0.1488 | Accuracy: 0.6394 | F1: 0.2649\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f0c981f414d49988c0c9d7b793ebb05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3/3 | Loss: 0.0265 | Accuracy: 0.6365 | F1: 0.2677\n"
          ]
        }
      ],
      "source": [
        "# Train models\n",
        "model1 = trian(model1, dataloader_roberta, epochs=7, learning_rate=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e36a8fbe66b341d283ed538064f0f482",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/7 | Loss: 0.5087 | Accuracy: 0.7492 | F1: 0.0039\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3d84b78749b44cabdfae39658dd616e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2/7 | Loss: 0.3477 | Accuracy: 0.7111 | F1: 0.1272\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d41b13dcf3a8411ab58f334a9127fb33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3/7 | Loss: 0.4841 | Accuracy: 0.6701 | F1: 0.2242\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62e3f7d2cf0b4ac3b2a8d9156e5b1df6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4/7 | Loss: 0.1441 | Accuracy: 0.6553 | F1: 0.2416\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7438a7f409a24e6b987cbf5708a4553a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 5/7 | Loss: 0.7052 | Accuracy: 0.6489 | F1: 0.2508\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "188dcacf8dd849338e69b7372ea53352",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 6/7 | Loss: 0.1064 | Accuracy: 0.6498 | F1: 0.2593\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac09f912a4264623868bbcd1ccce4e22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 7/7 | Loss: 0.0627 | Accuracy: 0.6458 | F1: 0.2619\n"
          ]
        }
      ],
      "source": [
        "model2 = trian(model2, dataloader_bertweet, epochs=7, learning_rate=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0345da59bad469fb713faf99e7d8e6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/3 | Loss: 0.7745 | Accuracy: 0.7472 | F1: 0.0128\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb60f07b2126434f875184b5e1579bdd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2/3 | Loss: 0.5254 | Accuracy: 0.7318 | F1: 0.0589\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3fc34362494430581a9f90b38334cbe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3/3 | Loss: 0.2870 | Accuracy: 0.6588 | F1: 0.2273\n"
          ]
        }
      ],
      "source": [
        "model3 = trian(model3, dataloader_deberta, epochs=3, learning_rate=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fdf404beec04dcd8043b49874021c91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/5 | Loss: 0.7236 | Accuracy: 0.7141 | F1: 0.1344\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3cd81626852d415396be72a02a4a211d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2/5 | Loss: 0.3141 | Accuracy: 0.6729 | F1: 0.2181\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2338c59e755b445b9c24478cb29e4940",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3/5 | Loss: 0.4340 | Accuracy: 0.6633 | F1: 0.2290\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e67fd7397e44c3ea756014740f2e4a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4/5 | Loss: 0.2646 | Accuracy: 0.6595 | F1: 0.2410\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0fe0ea73a6c4f9580ec033b3528ce03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 5/5 | Loss: 0.1246 | Accuracy: 0.6539 | F1: 0.2452\n"
          ]
        }
      ],
      "source": [
        "model4 = trian(model4, dataloader_bertweet_irony, epochs=5, learning_rate=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generate_pred_from_test_file([model2, model3, model4],\n",
        "                             ['finiteautomata/bertweet-base-sentiment-analysis', 'microsoft/deberta-v3-base', 'pysentimiento/bertweet-irony'],\n",
        "                             'iSarcasmEval/test/task_A_En_test.csv', 'output-234.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e1256ef24e0481ab752aa948b93f65f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1400 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "generate_pred_from_test_file([model1], \n",
        "                             ['roberta-base'], \n",
        "                             'iSarcasmEval/test/task_A_En_test.csv', 'output.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generate_pred_from_test_file([model1, model2, model3, model4],\n",
        "                                ['roberta-base', 'finiteautomata/bertweet-base-sentiment-analysis', 'microsoft/deberta-v3-base', 'pysentimiento/bertweet-irony'],\n",
        "                                'iSarcasmEval/test/task_A_En_test.csv', 'output-1234.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.362116991643454"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_f1('iSarcasmEval/test/task_A_En_test.csv', 'output.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.485207100591716"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_f1('iSarcasmEval/test/task_A_En_test.csv', 'output-234.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
